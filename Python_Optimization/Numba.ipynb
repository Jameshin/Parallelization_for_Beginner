{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ac7226-8a19-4301-a648-9e173ecb9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Note the use of an `out` array. CUDA kernels written with `@cuda.jit` do not return values,\n",
    "# just like their C counterparts. Also, no explicit type signature is required with @cuda.jit\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    \n",
    "    # The actual values of the following CUDA-provided variables for thread and block indices,\n",
    "    # like function parameters, are not known until the kernel is launched.\n",
    "    \n",
    "    # This calculation gives a unique thread index within the entire grid (see the slides above for more)\n",
    "    idx = cuda.grid(1)          # 1 = one dimensional thread grid, returns a single value.\n",
    "                                # This Numba-provided convenience function is equivalent to\n",
    "                                # `cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x`\n",
    "\n",
    "    # This thread will do the work on the data element with the same index as its own\n",
    "    # unique index within the grid.\n",
    "    out[idx] = x[idx] + y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feeb2a46-e78f-486a-b733-b6f0145c305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 4096\n",
    "x = np.arange(n).astype(np.int32) # [0...4095] on the host\n",
    "y = np.ones_like(x)               # [1...1] on the host\n",
    "\n",
    "d_x = cuda.to_device(x) # Copy of x on the device\n",
    "d_y = cuda.to_device(y) # Copy of y on the device\n",
    "d_out = cuda.device_array_like(d_x) # Like np.array_like, but for device arrays\n",
    "\n",
    "# Because of how we wrote the kernel above, we need to have a 1 thread to one data element mapping,\n",
    "# therefore we define the number of threads in the grid (128*32) to equal n (4096).\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90171386-68f9-46e7-8136-d05f6fcd7280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KISTI\\anaconda3\\lib\\site-packages\\numba\\cuda\\dispatcher.py:488: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 4094 4095 4096]\n"
     ]
    }
   ],
   "source": [
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "cuda.synchronize()\n",
    "print(d_out.copy_to_host()) # Should be [1...4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09cc7020-a3a3-4d6f-9beb-bf9889ffecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KISTI\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:885: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA @vectorize 계산 시간: 0.39950538초\n",
      "CUDA @cuda.jit 계산 시간: 0.34300160초\n",
      "Numpy 계산 시간: 0.52499819초\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import vectorize, cuda, float32\n",
    "import math\n",
    "import time\n",
    "\n",
    "# CUDA @vectorize 데코레이터를 사용한 arctan 함수\n",
    "@vectorize([float32(float32)], target='cuda')\n",
    "def arctan_cuda_vectorize(x):\n",
    "    return math.atan(x)\n",
    "\n",
    "# CUDA @cuda.jit 데코레이터를 사용한 arctan 함수\n",
    "@cuda.jit\n",
    "def arctan_cuda_jit(x, result):\n",
    "    i = cuda.grid(1)  # 스레드 인덱스 계산\n",
    "    if i < x.size:\n",
    "        result[i] = math.atan(x[i])\n",
    "\n",
    "# Numpy로 arctan 계산\n",
    "def arctan_numpy(x):\n",
    "    return np.arctan(x)\n",
    "\n",
    "# 입력 데이터 생성 (큰 배열로 성능 테스트)\n",
    "x = np.linspace(-1, 1, 100000000, dtype=np.float32)\n",
    "\n",
    "# CUDA @vectorize 시간 측정\n",
    "start_cuda_vectorize = time.time()\n",
    "arctan_cuda_vectorize_result = arctan_cuda_vectorize(x)\n",
    "end_cuda_vectorize = time.time()\n",
    "\n",
    "# CUDA @cuda.jit 시간 측정\n",
    "arctan_cuda_jit_result = np.empty_like(x)\n",
    "threads_per_block = 512\n",
    "blocks_per_grid = (x.size + (threads_per_block - 1)) // threads_per_block\n",
    "start_cuda_jit = time.time()\n",
    "arctan_cuda_jit[blocks_per_grid, threads_per_block](x, arctan_cuda_jit_result)\n",
    "cuda.synchronize()  # CUDA 커널 동기화\n",
    "end_cuda_jit = time.time()\n",
    "\n",
    "# Numpy 시간 측정\n",
    "start_numpy = time.time()\n",
    "arctan_numpy_result = arctan_numpy(x)\n",
    "end_numpy = time.time()\n",
    "\n",
    "# 시간 출력\n",
    "print(\"CUDA @vectorize 계산 시간: {:.8f}초\".format(end_cuda_vectorize - start_cuda_vectorize))\n",
    "print(\"CUDA @cuda.jit 계산 시간: {:.8f}초\".format(end_cuda_jit - start_cuda_jit))\n",
    "print(\"Numpy 계산 시간: {:.8f}초\".format(end_numpy - start_numpy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f2e6434-1af9-41ae-8923-57221588719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "n = 2048*2048 # 4M\n",
    "\n",
    "# 2D blocks\n",
    "threads_per_block = (32, 32)\n",
    "# 2D grid\n",
    "blocks = (64, 64)\n",
    "\n",
    "# 2048x2048 input matrices\n",
    "a = np.arange(n).reshape(2048,2048).astype(np.float32)\n",
    "b = a.copy().astype(np.float32)\n",
    "\n",
    "# 2048x2048 0-initialized output matrix\n",
    "out = np.zeros_like(a).astype(np.float32)\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_out = cuda.to_device(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e8899-6c1e-4f77-85f6-2ecd8c52c36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044dd79-dfee-4010-a808-abc711f5dd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
